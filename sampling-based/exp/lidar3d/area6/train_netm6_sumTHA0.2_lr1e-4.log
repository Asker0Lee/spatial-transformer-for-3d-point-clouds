I0821 15:40:33.476923 20617 _caffe.cpp:68] Using devices [0]
[0]
Using network defined at area6_netm6_sumTHA0.2.prototxt
I0821 15:40:34.409029 25293 upgrade_proto.cpp:1084] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /mnt/lustre/wangjiayun/repos/splatnet/exp/lidar3d/area6/6_solver.prototxt
I0821 15:40:34.409142 25293 upgrade_proto.cpp:1091] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0821 15:40:34.409152 25293 upgrade_proto.cpp:1093] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0821 15:40:35.206009 25293 solver.cpp:45] Initializing solver from parameters: 
train_net: "area6_netm6_sumTHA0.2.prototxt"
test_net: "area6_netm6_sumTHA0.2.prototxt"
test_iter: 10
test_interval: 50
base_lr: 0.0001
display: 1
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 2000
snapshot: 50
snapshot_prefix: "/mnt/lustre/wangjiayun/repos/splatnet/exp/lidar3d/area6/6_netm6_sumTHA0.2_lr1e-4"
solver_mode: GPU
random_seed: 0
debug_info: false
iter_size: 10
momentum2: 0.999
type: "Adam"
I0821 15:40:35.208637 25293 solver.cpp:92] Creating training net from train_net file: area6_netm6_sumTHA0.2.prototxt
I0821 15:40:35.253175 25293 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0821 15:40:35.253763 25293 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "dataset_lidar"
    layer: "InputShapenet"
    param_str: "{\'sample_size\': 4096, \'test_area\': \'6\', \'batch_size\': 12, \'feat_dims\': \'x_y_z_r_g_b\', \'subset\': \'train\', \'root\': \'../../data/shapenet_ericyi_ply\', \'jitter_xyz\': 0.01, \'jitter_stretch\': 0.05, \'jitter_rotation\': 5.0}"
  }
}
layer {
  name: "data_feat"
  type: "Python"
  bottom: "data"
  top: "data_feat"
  python_param {
    module: "custom_layers"
    layer: "PickAndScale2"
    param_str: "0_1_2"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "bn1"
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "bn1"
  top: "conv1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1a"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "bn1a"
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "bn1a"
  top: "bn1a"
}
layer {
  name: "fconv1"
  type: "Convolution"
  bottom: "bn1a"
  top: "fconv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fconv1_"
  type: "ReLU2"
  bottom: "fconv1"
  top: "fconv1_"
  relu2_param {
    threshold: 0.2
  }
}
layer {
  name: "fconv1__"
  type: "ReLU3"
  bottom: "fconv1_"
  top: "fconv1__"
  relu2_param {
    threshold: -0.2
  }
}
layer {
  name: "feat1"
  type: "Eltwise"
  bottom: "data_feat"
  bottom: "fconv1__"
  top: "feat1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "data_lattice0"
  type: "Python"
  bottom: "feat1"
  top: "data_lattice0"
  python_param {
    module: "custom_layers"
    layer: "PickAndScale2"
    param_str: "0*48_1*48_2*48"
  }
}
layer {
  name: "conv2"
  type: "Permutohedral"
  bottom: "bn1a"
  bottom: "data_lattice0"
  bottom: "data_lattice0"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  permutohedral_param {
    num_output: 64
    neighborhood_size: 1
    filter_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    norm_type: AFTER
    offset_type: NONE
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "bn2"
}
layer {
  name: "fconv2"
  type: "Convolution"
  bottom: "bn2"
  top: "fconv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fconv2_"
  type: "ReLU2"
  bottom: "fconv2"
  top: "fconv2_"
  relu2_param {
    threshold: 0.2
  }
}
layer {
  name: "fconv2__"
  type: "ReLU3"
  bottom: "fconv2_"
  top: "fconv2__"
  relu2_param {
    threshold: -0.2
  }
}
layer {
  name: "feat2"
  type: "Eltwise"
  bottom: "data_feat"
  bottom: "fconv2__"
  top: "feat2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "data_lattice1"
  type: "Python"
  bottom: "feat2"
  top: "data_lattice1"
  python_param {
    module: "custom_layers"
    layer: "PickAndScale2"
    param_str: "0*24_1*24_2*24"
  }
}
layer {
  name: "conv3"
  type: "Permutohedral"
  bottom: "bn2"
  bottom: "data_lattice1"
  bottom: "data_lattice1"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  permutohedral_param {
    num_output: 128
    neighborhood_size: 1
    filter_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    norm_type: AFTER
    offset_type: NONE
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "bn3"
  top: "bn3"
}
layer {
  name: "fconv3"
  type: "Convolution"
  bottom: "bn3"
  top: "fconv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fconv3_"
  type: "ReLU2"
  bottom: "fconv3"
  top: "fconv3_"
  relu2_param {
    threshold: 0.2
  }
}
layer {
  name: "fconv3__"
  type: "ReLU3"
  bottom: "fconv3_"
  top: "fconv3__"
  relu2_param {
    threshold: -0.2
  }
}
layer {
  name: "feat3"
  type: "Eltwise"
  bottom: "data_feat"
  bottom: "fconv3__"
  top: "feat3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "data_lattice2"
  type: "Python"
  bottom: "feat3"
  top: "data_lattice2"
  python_param {
    module: "custom_layers"
    layer: "PickAndScale2"
    param_str: "0*12_1*12_2*12"
  }
}
layer {
  name: "conv4"
  type: "Permutohedral"
  bottom: "bn3"
  bottom: "data_lattice2"
  bottom: "data_lattice2"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  permutohedral_param {
    num_output: 256
    neighborhood_size: 1
    filter_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    norm_type: AFTER
    offset_type: NONE
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "bn4"
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "bn4"
  top: "bn4"
}
layer {
  name: "fconv4"
  type: "Convolution"
  bottom: "bn4"
  top: "fconv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fconv4_"
  type: "ReLU2"
  bottom: "fconv4"
  top: "fconv4_"
  relu2_param {
    threshold: 0.2
  }
}
layer {
  name: "fconv4__"
  type: "ReLU3"
  bottom: "fconv4_"
  top: "fconv4__"
  relu2_param {
    threshold: -0.2
  }
}
layer {
  name: "feat4"
  type: "Eltwise"
  bottom: "data_feat"
  bottom: "fconv4__"
  top: "feat4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "data_lattice3"
  type: "Python"
  bottom: "feat4"
  top: "data_lattice3"
  python_param {
    module: "custom_layers"
    layer: "PickAndScale2"
    param_str: "0*6_1*6_2*6"
  }
}
layer {
  name: "conv5"
  type: "Permutohedral"
  bottom: "bn4"
  bottom: "data_lattice3"
  bottom: "data_lattice3"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  permutohedral_param {
    num_output: 256
    neighborhood_size: 1
    filter_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    norm_type: AFTER
    offset_type: NONE
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "bn5"
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "bn5"
  top: "bn5"
}
layer {
  name: "fconv5"
  type: "Convolution"
  bottom: "bn5"
  top: "fconv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fconv5_"
  type: "ReLU2"
  bottom: "fconv5"
  top: "fconv5_"
  relu2_param {
    threshold: 0.2
  }
}
layer {
  name: "fconv5__"
  type: "ReLU3"
  bottom: "fconv5_"
  top: "fconv5__"
  relu2_param {
    threshold: -0.2
  }
}
layer {
  name: "feat5"
  type: "Eltwise"
  bottom: "data_feat"
  bottom: "fconv5__"
  top: "feat5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "data_lattice4"
  type: "Python"
  bottom: "feat5"
  top: "data_lattice4"
  python_param {
    module: "custom_layers"
    layer: "PickAndScale2"
    param_str: "0*3_1*3_2*3"
  }
}
layer {
  name: "conv6"
  type: "Permutohedral"
  bottom: "bn5"
  bottom: "data_lattice4"
  bottom: "data_lattice4"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  permutohedral_param {
    num_output: 256
    neighborhood_size: 1
    filter_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
    group: 1
    norm_type: AFTER
    offset_type: NONE
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "conv6"
  top: "bn6"
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "bn6"
  top: "bn6"
}
layer {
  name: "concat6"
  type: "Concat"
  bottom: "bn6"
  bottom: "bn2"
  bottom: "bn3"
  bottom: "bn4"
  bottom: "bn5"
  top: "concat6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "concat6"
  top: "conv7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "conv7"
  top: "bn7"
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "bn7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "bn7"
  top: "conv8"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 13
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv8"
  bottom: "label"
  top: "accuracy"
}
I0821 15:40:35.260587 25293 layer_factory.hpp:77] Creating layer data
I0821 15:40:35.279871 25293 net.cpp:84] Creating Layer data
I0821 15:40:35.280478 25293 net.cpp:380] data -> data
I0821 15:40:35.282338 25293 net.cpp:380] data -> label
